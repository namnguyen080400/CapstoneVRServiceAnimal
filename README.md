This Unity project features a voice- and gesture-controlled virtual dog that responds to natural language and hand gestures in a Passthrough XR environment. Built with XR Interaction Toolkit, Wit.ai, and Meta XR SDK, the dog can follow commands, perform actions, and interact with the player.

**Features Implemented**
- Voice control via Wit.ai
- Hand gesture recognition using XR Hands
- Dog behaviors: walk, sit, bark, wag tail, follow, approach
- â€œFollow meâ€ and â€œCome hereâ€ support
- Interactive animations and sound effects
- Passthrough AR (real-world background)

**Voice Commands**

go left -> Dog walks left

go right -> Dog walks right

go forward -> Dog walks forward

go backward -> Dog walks backward

go eat -> Dog eats

pick the ball -> Dog walks to and picks up the ball

move ball -> Ball moves, dog fetches it

I feel sad -> Dog whines and approaches

bad dog -> Dog barks loudly

wag tail -> Dog wags tail

sit down -> Dog sits

follow me -> Dog follows you

come here -> Dog walks to you


**Hand Gesture Mapping**

Open Palm -> Dog walks to you

Thumbs Up -> Dog sits

Thumbs Down -> Dog barks angrily

Shaka (ðŸ¤™) -> Dog wags tail


**In Progress / Planned Features**

Dog responds with speech bubbles (using AI-generated replies)

Physics-based ball grab & throw (not yet implemented)

More natural dog movement and animation blending

